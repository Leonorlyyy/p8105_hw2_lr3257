p8105_hw2_lr3257
================
Leonor Rui
2024-09-30

# Homework 2

## Problem 1

``` r
### read data file
NYC_df = 
  read_csv("data/NYCsubway.csv",  na = c("NA", "", "."), show_col_types = FALSE) |>
  janitor::clean_names() |>
  mutate(
    entry = ifelse(entry == "YES", TRUE, FALSE)
    )
```

### Description:

There are 32 variables contained in this dataset: division (character),
line (character), station_name (character), station_latitude (double),
station_longtitude (double), route 1-7 (character), route 8-11 (double),
entrance_type (character), entry (character), exit_only (character),
vending (character), staffing (character), staff_hours (character), ada
(logical), ada_notes (character), free_crossover (logical),
north_south_street (character), east_west_street (character), corner
(character), entrance_latitude (double), entrance_longitude (double),
station_location (character), entrance_location (character).

So far, I have used the janitor::clean_names() function for some basic
cleanings about the column names, including converting all column names
to lowercase, replacing spaces and special characters with underscores,
etc. I have also defined the “NA”, “,”, and “.” values in the dataset to
be na for the convenience of later data analysis.

The dimension of the dataset now is 1868 rows x 32 columns. Despite I
have changed the entry variable from character to logical type, the
dataset is still not tidy, as there are many more character variables
that could be turned into logical variables, and there are many NA data
in it that may interfere further data analysis.

- How many distinct stations are there?

``` r
distinct(NYC_df, line, station_name)
```

    ## # A tibble: 465 × 2
    ##    line     station_name            
    ##    <chr>    <chr>                   
    ##  1 4 Avenue 25th St                 
    ##  2 4 Avenue 36th St                 
    ##  3 4 Avenue 45th St                 
    ##  4 4 Avenue 53rd St                 
    ##  5 4 Avenue 59th St                 
    ##  6 4 Avenue 77th St                 
    ##  7 4 Avenue 86th St                 
    ##  8 4 Avenue 95th St                 
    ##  9 4 Avenue 9th St                  
    ## 10 4 Avenue Atlantic Av-Barclays Ctr
    ## # ℹ 455 more rows

There are 465 distinct stations.

- How many stations are ADA compliant?

``` r
filter(NYC_df, ada == TRUE) |>
  distinct(line, station_name)
```

    ## # A tibble: 84 × 2
    ##    line            station_name                  
    ##    <chr>           <chr>                         
    ##  1 4 Avenue        Atlantic Av-Barclays Ctr      
    ##  2 4 Avenue        DeKalb Av                     
    ##  3 4 Avenue        Pacific St                    
    ##  4 42nd St Shuttle Grand Central                 
    ##  5 6 Avenue        34th St                       
    ##  6 6 Avenue        47-50th Sts Rockefeller Center
    ##  7 6 Avenue        Church Av                     
    ##  8 63rd Street     21st St                       
    ##  9 63rd Street     Lexington Av                  
    ## 10 63rd Street     Roosevelt Island              
    ## # ℹ 74 more rows

84 stations are ADA compliant.

- What proportion of station entrances / exits without vending allow
  entrance?

``` r
vending_df = filter(NYC_df, vending == "NO")
vending_entry_df = filter(vending_df, entry == "TRUE")
nrow(vending_entry_df)/nrow(vending_df)
```

    ## [1] 0.3770492

About 37.7% of stations without vending allow entrance.

- Reformat data so that route number and route name are distinct
  variables. How many distinct stations serve the A train? Of the
  stations that serve the A train, how many are ADA compliant?

``` r
NYC_df = mutate(
    NYC_df,
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
  ) |>
  pivot_longer(
  cols = route1:route11,
  names_to = "route_number",
  values_to = "route_name",
  names_prefix = "route") |>
  drop_na(route_name)
print(NYC_df)
```

    ## # A tibble: 4,270 × 23
    ##    division line   station_name station_latitude station_longitude entrance_type
    ##    <chr>    <chr>  <chr>                   <dbl>             <dbl> <chr>        
    ##  1 BMT      4 Ave… 25th St                  40.7             -74.0 Stair        
    ##  2 BMT      4 Ave… 25th St                  40.7             -74.0 Stair        
    ##  3 BMT      4 Ave… 36th St                  40.7             -74.0 Stair        
    ##  4 BMT      4 Ave… 36th St                  40.7             -74.0 Stair        
    ##  5 BMT      4 Ave… 36th St                  40.7             -74.0 Stair        
    ##  6 BMT      4 Ave… 36th St                  40.7             -74.0 Stair        
    ##  7 BMT      4 Ave… 36th St                  40.7             -74.0 Stair        
    ##  8 BMT      4 Ave… 36th St                  40.7             -74.0 Stair        
    ##  9 BMT      4 Ave… 45th St                  40.6             -74.0 Stair        
    ## 10 BMT      4 Ave… 45th St                  40.6             -74.0 Stair        
    ## # ℹ 4,260 more rows
    ## # ℹ 17 more variables: entry <lgl>, exit_only <chr>, vending <chr>,
    ## #   staffing <chr>, staff_hours <chr>, ada <lgl>, ada_notes <chr>,
    ## #   free_crossover <lgl>, north_south_street <chr>, east_west_street <chr>,
    ## #   corner <chr>, entrance_latitude <dbl>, entrance_longitude <dbl>,
    ## #   station_location <chr>, entrance_location <chr>, route_number <chr>,
    ## #   route_name <chr>

``` r
A_df = filter(NYC_df, route_name == "A")
A_ada_df = filter(A_df, ada == "TRUE")
A_distinct = distinct(A_df, line, station_name)
A_ada_distinct = distinct(A_ada_df, line, station_name)
```

60 distinct stations serve the A train. Out of these stations, 17
stations are ADA compliant.

## Problem 2

### Mr. Trash Wheel sheet

``` r
Mr_TW = read_excel("data/Trash_wheel.xlsx", sheet = "Mr. Trash Wheel") |>
  janitor::clean_names() |>
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    year = as.numeric(year)
  ) |>
  select(-(x15:x16)) |>
  slice(1:(n()-1))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
print(Mr_TW)
```

    ## # A tibble: 652 × 14
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 642 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

### Professor Trash Wheel

``` r
Prof_TW = read_excel("data/Trash_wheel.xlsx", sheet = "Professor Trash Wheel")|>
  janitor::clean_names() |>
  slice(1:(n()-1))
print(Prof_TW)
```

    ## # A tibble: 120 × 13
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # ℹ 110 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

### Gwynnda

``` r
G_TW = read_excel("data/Trash_wheel.xlsx", sheet = "Gwynnda Trash Wheel") |>
  janitor::clean_names() |>
  slice(1:(n()-2))
print(G_TW)
```

    ## # A tibble: 262 × 12
    ##    dumpster month   year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 July    2021 2021-07-03 00:00:00        0.93                 15
    ##  2        2 July    2021 2021-07-07 00:00:00        2.26                 15
    ##  3        3 July    2021 2021-07-07 00:00:00        1.62                 15
    ##  4        4 July    2021 2021-07-16 00:00:00        1.76                 15
    ##  5        5 July    2021 2021-07-30 00:00:00        1.53                 15
    ##  6        6 August  2021 2021-08-11 00:00:00        2.06                 15
    ##  7        7 August  2021 2021-08-14 00:00:00        1.9                  15
    ##  8        8 August  2021 2021-08-16 00:00:00        2.16                 15
    ##  9        9 August  2021 2021-08-16 00:00:00        2.6                  15
    ## 10       10 August  2021 2021-08-17 00:00:00        3.21                 15
    ## # ℹ 252 more rows
    ## # ℹ 6 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>

### Combine datasets

``` r
Mr_TW = mutate(Mr_TW, trash_wheel = "Mr. Trash Wheel") |>
  relocate (trash_wheel)

Prof_TW = Prof_TW |>
  add_column(sports_balls = NA, .before = 13)|>
  mutate(
    trash_wheel = "Professor Trash Wheel"
  ) |>
  relocate(trash_wheel)

G_TW = G_TW |>
  add_column(sports_balls = NA, .before = 12) |>
  add_column(glass_bottles = NA, .after = 9) |>
  mutate(
    trash_wheel = "Gwynnda Trash Wheel"
  ) |>
  relocate(trash_wheel)

combined_TW = bind_rows(Mr_TW, Prof_TW, G_TW)
print(combined_TW)
```

    ## # A tibble: 1,034 × 15
    ##    trash_wheel     dumpster month  year date                weight_tons
    ##    <chr>              <dbl> <chr> <dbl> <dttm>                    <dbl>
    ##  1 Mr. Trash Wheel        1 May    2014 2014-05-16 00:00:00        4.31
    ##  2 Mr. Trash Wheel        2 May    2014 2014-05-16 00:00:00        2.74
    ##  3 Mr. Trash Wheel        3 May    2014 2014-05-16 00:00:00        3.45
    ##  4 Mr. Trash Wheel        4 May    2014 2014-05-17 00:00:00        3.1 
    ##  5 Mr. Trash Wheel        5 May    2014 2014-05-17 00:00:00        4.06
    ##  6 Mr. Trash Wheel        6 May    2014 2014-05-20 00:00:00        2.71
    ##  7 Mr. Trash Wheel        7 May    2014 2014-05-21 00:00:00        1.91
    ##  8 Mr. Trash Wheel        8 May    2014 2014-05-28 00:00:00        3.7 
    ##  9 Mr. Trash Wheel        9 June   2014 2014-06-05 00:00:00        2.52
    ## 10 Mr. Trash Wheel       10 June   2014 2014-06-11 00:00:00        3.76
    ## # ℹ 1,024 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

### Description:

There are 15 variables and 1034 observations in this final combined
dataset. Important variables include weight_tons (double, weight of
trash the wheel collected in tons), volume_cubic_yars (numeric, volume
of trash collected in cubic yards), homes_powered (double, number of
homes powered by energy generated by the trash), and some variables
dedicated to the number of a certain kind of trash the wheel collected
(e.g. plastic_bottles, wrappers). It’s noteworthy that only Mr. Trash
Wheel has the “sports_balls” variable and Gwynnda Trash Wheel does not
have the “glass_bottles” variable, meaning we need to create a new and
empty variable for Professor Trash Wheel and two such variables for
Gwynnda Trash Wheel.

The total weight of trash collected by Professor Trash Wheel is NA tons.

``` r
filter(G_TW, month == "June", year == 2022) |>
  select(cigarette_butts) |>
  sum()
```

    ## [1] 18120

The total number of cigarette butts collected by Gwynnda in June of 2022
is 18120.

## Problem 3

Import datasets, basic clean ups

``` r
bakers_df = read_csv("data/gbb_datasets/bakers.csv", na = c("N/A", "", "."), show_col_types = FALSE) |>
  janitor::clean_names() 

bakes_df = read_csv("data/gbb_datasets/bakes.csv", na = c("N/A", "", "."), show_col_types = FALSE) |>
  janitor::clean_names()

results_df = 
  read_csv("data/gbb_datasets/results.csv", na = c("NA", "", "."), show_col_types = FALSE, skip = 2) |>
  janitor::clean_names() |>
  drop_na(result) |>
  mutate(result = case_when(
    result == "IN" ~ "Stayed in",
    result == "OUT" ~ "Eliminated",
    result == "STAR BAKER" ~ "Star Baker",
    result == "WINNER" ~ "Series Winner",
    result == "Runner-up" ~ "Series Runner-up",
    result == "WD" ~ "Withdrew",
    TRUE ~ result))
```

``` r
## join results_df and bakes_df first
gbb_df = 
  left_join(results_df, bakes_df, by = c("series", "episode", "baker")) 

## check if left any rows out
bakes_filtered = anti_join(bakes_df, gbb_df, by = "baker")

## add the left rows
gbb_df = bind_rows(gbb_df, bakes_filtered) |>
  mutate(baker = ifelse(baker == '"Jo"', "Jo", baker))

## modify the datasets for further combination
bakers_df = bakers_df |>
  separate(baker_name, into = c("baker_first_name", "baker_last_name"), sep = " ")

## join bakers_df to the combined dataset, organize variables and observations
gbb_df = rename(gbb_df, baker_first_name = baker) |>
  left_join(bakers_df, by = c("baker_first_name", "series")) |>
  relocate(baker_first_name, baker_last_name, series, episode, baker_age, baker_occupation, hometown) |>
  arrange(baker_first_name, series)

print(gbb_df)
```

    ## # A tibble: 718 × 11
    ##    baker_first_name baker_last_name series episode baker_age baker_occupation 
    ##    <chr>            <chr>            <dbl>   <dbl>     <dbl> <chr>            
    ##  1 Ali              Imdad                4       1        25 Charity worker   
    ##  2 Ali              Imdad                4       2        25 Charity worker   
    ##  3 Ali              Imdad                4       3        25 Charity worker   
    ##  4 Ali              Imdad                4       4        25 Charity worker   
    ##  5 Alice            Fevronia            10       1        28 Geography teacher
    ##  6 Alice            Fevronia            10       2        28 Geography teacher
    ##  7 Alice            Fevronia            10       3        28 Geography teacher
    ##  8 Alice            Fevronia            10       4        28 Geography teacher
    ##  9 Alice            Fevronia            10       5        28 Geography teacher
    ## 10 Alice            Fevronia            10       6        28 Geography teacher
    ## # ℹ 708 more rows
    ## # ℹ 5 more variables: hometown <chr>, technical <dbl>, result <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
write_csv(gbb_df, "data/gbb_datasets/combined_gbb.csv")
```

### Description

For data cleaning, I first used the janitor::clean() function to unite
the format of the variable names and define NA values. Since the result
variable in results_df continues to show values even after the baker was
ousted in the previous episode, which leads it to hold many unnecessary
NA values, I also omit these NA result values to simplify the dataframe.
Since the results are abbreviations and the meaning of them are included
in the first line that makes the dataframe untidy, I changed the
abbreviations to their direct meanings. Then, considering there are many
duplicate variables results_df and bakes_df hold (series, episode,
baker), I first join these two dataframes by these three variables.
However, when I check the corectness across datasets using the
anti_join() function, I found that there is one baker named “Jo” who is
not in the results_df but in the bakes_df, so I appended rows of this
baker to the combined dataframe additionally. For the bakers_df, since
its baker name variable contains both the baker’s first and last names,
to make it in line with the other two dataframes, I separate this
variable into two variables (baker_first_name and baker_last_name), and
rename the baker variable in the combined dataset to baker_first_name.
This makes the join of bakers_df into the combined gbb_df much easier.
Lastly, for the readability of the dataframe, I chose to reorder the
variables to put the names of the bakers at front and the results and
signature bakes at last. Also, since one baker will appear in the same
series for multiple times, for the tidiness of the dataframe, I arrange
the bakers’ names to be shown alphabetically.

The final dataset gbb_df has 718 observations and 11 variables,
including the bakers’ first name and last name, the series and episode
they appeared in, their age, occupation, hometown, technical scores,
signature bake, show stopper, and show results. Note that not all bakers
have information about all these variables, and those lost information
are marked as NA.

- Create a reader-friendly table showing the star baker or winner of
  each episode in Seasons 5 through 10. Comment on this table – were
  there any predictable overall winners? Any surprises?

``` r
star_winner = gbb_df|>
  filter(result %in% c("Star Baker", "Series Winner"), series %in% c(5, 6, 7, 8, 9, 10)) |>
  relocate(result) |>
  arrange(series)

star_winner_table = as_tibble(star_winner)
print(star_winner_table)
```

    ## # A tibble: 60 × 11
    ##    result        baker_first_name baker_last_name series episode baker_age
    ##    <chr>         <chr>            <chr>            <dbl>   <dbl>     <dbl>
    ##  1 Star Baker    Chetna           Makan                5       6        35
    ##  2 Star Baker    Kate             Henry                5       5        41
    ##  3 Star Baker    Luis             Troyano              5       3        42
    ##  4 Star Baker    Nancy            Birtwhistle          5       1        60
    ##  5 Series Winner Nancy            Birtwhistle          5      10        60
    ##  6 Star Baker    Richard          Burr                 5       2        38
    ##  7 Star Baker    Richard          Burr                 5       4        38
    ##  8 Star Baker    Richard          Burr                 5       7        38
    ##  9 Star Baker    Richard          Burr                 5       8        38
    ## 10 Star Baker    Richard          Burr                 5       9        38
    ## # ℹ 50 more rows
    ## # ℹ 5 more variables: baker_occupation <chr>, hometown <chr>, technical <dbl>,
    ## #   signature_bake <chr>, show_stopper <chr>

As we can see from the table above, for series 6-9, the series winners
have all been the star baker for multiple episodes, so their winnings
are largely predictable. However, the series winner in series 5, Nancy
Birtwhistle, has only been the star baker once, and that the series
winner in series 10, David Atherton, even has not been a star baker for
a single time in this series. People would have predicted other star
bakers like Richard Burr (5) and Steph Blackwell (10) to be the series
winner in their respective series, so these two winners are quite
surprises.

- Import, clean, tidy, and organize the viewership data in viewers.csv.
  Show the first 10 rows of this dataset. What was the average
  viewership in Season 1? In Season 5?

``` r
viewers_df = read_csv("data/gbb_datasets/viewers.csv", na = "NA", show_col_types = FALSE) |>
  janitor::clean_names() |>
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewership",
    names_prefix = "series_"
      ) |>
  mutate(series = as.numeric(series)) |>
  relocate(series) |>
  arrange(series)

print(viewers_df, n = 10)
```

    ## # A tibble: 100 × 3
    ##    series episode viewership
    ##     <dbl>   <dbl>      <dbl>
    ##  1      1       1       2.24
    ##  2      1       2       3   
    ##  3      1       3       3   
    ##  4      1       4       2.6 
    ##  5      1       5       3.03
    ##  6      1       6       2.75
    ##  7      1       7      NA   
    ##  8      1       8      NA   
    ##  9      1       9      NA   
    ## 10      1      10      NA   
    ## # ℹ 90 more rows

``` r
season_1 = filter(viewers_df, series == 1)
season_5 = filter(viewers_df, series == 5)

sum(na.omit(select(season_1, viewership)))/sum(!is.na(select(season_1, viewership)))
```

    ## [1] 2.77

``` r
sum(select(season_5, viewership))/nrow(season_5)
```

    ## [1] 10.0393

The average viewership in Season 1 is 2.77, in Season 5 is 10.0393
